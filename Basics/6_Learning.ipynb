{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CIFfSpcNIMho"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIFfSpcNIMho"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Brb4EpQuIC_e"
      },
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "train_labels = []\n",
        "train_samples = []\n",
        "\n",
        "for i in range(1000):\n",
        "  random_younger = randint(13, 64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(0)\n",
        "\n",
        "  random_older = randint(65, 100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(1)\n",
        "\n",
        "for i in range(50):\n",
        "  random_younger = randint(13, 64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(1)\n",
        "\n",
        "  random_older = randint(65, 100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(0)\n",
        "\n",
        "\n",
        "train_labels = np.array(train_labels)\n",
        "train_samples = np.array(train_samples)\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_train_samples = scaler.fit_transform((train_samples).reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIbrM6sJIdV8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhOAEXgFIqtO"
      },
      "source": [
        "# <b> Learning </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiZDIk3kImlc"
      },
      "source": [
        "import keras\n",
        "from keras import backend as k\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers.core import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRYv5CPoImiP"
      },
      "source": [
        "# 1 input layer\n",
        "# 2 hidden dense layers\n",
        "# with 16 and 32 neurons respectively\n",
        "# and output layer with 2 units\n",
        "model = Sequential([\n",
        "                    Dense(16, input_shape=(1,), activation='relu'),  \n",
        "                    Dense(32, activation='relu'),\n",
        "                    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dej77BrzI2BR"
      },
      "source": [
        "once we have our model, the next thing we need to do before we can train it is to compile our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWPJAu8ZIme_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTFc96ZqImcG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6Go0whlI5S3"
      },
      "source": [
        "First parameter is an optimizer, SGD was a common optimizer. Here I'm using an optimizer called as Adam, and that is a variation of SGD.\n",
        "\n",
        "learning_rate -- we can also use \"lr\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o27HPoJ8ImZt"
      },
      "source": [
        "model.compile(Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIJyw8PBJCIw"
      },
      "source": [
        " This the actual function that is going to train the model\n",
        "\n",
        "<b>first parameter</b> -- training data. here scaled_train_samples is a numpy array that holds all of our data.\n",
        "\n",
        "<b>train_labels</b> -- again a numpy array that holds all the labels of the above training_data.\n",
        "\n",
        "<b>batch_size</b> -- how many pieces of data do we want tobe send to the model at once.\n",
        "\n",
        "<b>epochs</b> -- whenever we run this we're going to see there going to be 20 individual passes of the data through our model.\n",
        "\n",
        "<b>shuffle</b> -- this is just going to shuffle our data around in a different order with each epoch.\n",
        "\n",
        "<b>verbose</b> -- determines how much output we want to see whenever we train out model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHu05Im5ImXv"
      },
      "source": [
        "model.loss = 'sparse_categorical_crossentropy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uB4pqdZcJGVN",
        "outputId": "2c3116f1-524a-45af-8bed-979004a8a9da"
      },
      "source": [
        "model.loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sparse_categorical_crossentropy'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZaGbmH7JKoE"
      },
      "source": [
        "This is the actual function that is going to train our model.\n",
        "\n",
        "It accepts training_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AqfF_8XJIUW",
        "outputId": "7f22bcb2-4817-461d-d663-730ada7ffdc6"
      },
      "source": [
        "model.fit(scaled_train_samples, train_labels, batch_size=10, epochs=20, shuffle=True, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "210/210 - 1s - loss: 0.7038 - accuracy: 0.4795\n",
            "Epoch 2/20\n",
            "210/210 - 0s - loss: 0.6731 - accuracy: 0.6329\n",
            "Epoch 3/20\n",
            "210/210 - 0s - loss: 0.6445 - accuracy: 0.6429\n",
            "Epoch 4/20\n",
            "210/210 - 0s - loss: 0.6128 - accuracy: 0.6886\n",
            "Epoch 5/20\n",
            "210/210 - 0s - loss: 0.5782 - accuracy: 0.7395\n",
            "Epoch 6/20\n",
            "210/210 - 0s - loss: 0.5446 - accuracy: 0.7795\n",
            "Epoch 7/20\n",
            "210/210 - 0s - loss: 0.5109 - accuracy: 0.8138\n",
            "Epoch 8/20\n",
            "210/210 - 0s - loss: 0.4786 - accuracy: 0.8429\n",
            "Epoch 9/20\n",
            "210/210 - 0s - loss: 0.4490 - accuracy: 0.8548\n",
            "Epoch 10/20\n",
            "210/210 - 0s - loss: 0.4222 - accuracy: 0.8705\n",
            "Epoch 11/20\n",
            "210/210 - 0s - loss: 0.3985 - accuracy: 0.8886\n",
            "Epoch 12/20\n",
            "210/210 - 0s - loss: 0.3776 - accuracy: 0.8971\n",
            "Epoch 13/20\n",
            "210/210 - 0s - loss: 0.3599 - accuracy: 0.9014\n",
            "Epoch 14/20\n",
            "210/210 - 0s - loss: 0.3446 - accuracy: 0.9095\n",
            "Epoch 15/20\n",
            "210/210 - 0s - loss: 0.3319 - accuracy: 0.9086\n",
            "Epoch 16/20\n",
            "210/210 - 0s - loss: 0.3208 - accuracy: 0.9167\n",
            "Epoch 17/20\n",
            "210/210 - 0s - loss: 0.3115 - accuracy: 0.9162\n",
            "Epoch 18/20\n",
            "210/210 - 0s - loss: 0.3037 - accuracy: 0.9219\n",
            "Epoch 19/20\n",
            "210/210 - 0s - loss: 0.2972 - accuracy: 0.9238\n",
            "Epoch 20/20\n",
            "210/210 - 0s - loss: 0.2915 - accuracy: 0.9252\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff1cd0ca390>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7LLjpNRJNet"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}